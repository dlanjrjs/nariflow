{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nariflow import start_initializer\n",
    "\n",
    "start_initializer().initializer('tape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nariflow import Variable\n",
    "from nariflow import optimizer\n",
    "from nariflow import GradientTape\n",
    "#from nariflow import calc_gradient\n",
    "from nariflow import layer\n",
    "from nariflow.models import Model\n",
    "from nariflow import functions as f\n",
    "from nariflow.core import elementary_function as ef\n",
    "from nariflow.core import shape_function as sf\n",
    "from nariflow.utils import DataSet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "dataset_path = tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
    "                        extract=True, cache_dir='.')\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop un-used columns.\n",
    "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7383 train examples\n",
      "1846 validation examples\n",
      "2308 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processing = pd.concat([pd.get_dummies(train.loc[:, train.apply(lambda x : x.dtype == 'object')]),\n",
    "           train.loc[:,train.apply(lambda x : x.dtype != 'object')].apply(lambda x : (x - min(x)) / (max(x) - min(x)) )], \n",
    "          axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_processing.drop(['target'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processing = pd.concat([pd.get_dummies(test.loc[:, test.apply(lambda x : x.dtype == 'object')]),\n",
    "           test.loc[:,test.apply(lambda x : x.dtype != 'object')].apply(lambda x : (x - min(x)) / (max(x) - min(x)) )], \n",
    "          axis = 1)\n",
    "\n",
    "test_processing = pd.concat([pd.DataFrame(columns = train_processing.columns),\n",
    "           test_processing])[train_processing.columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(pd.get_dummies(test_processing.loc[:,'target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= test_processing.drop(['target'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(pd.get_dummies(train_processing.loc[:,'target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.2\n",
    "max_iter = 10000\n",
    "hidden_size = 200\n",
    "out_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models(Model):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.l1 = layer.Linear(hidden_size, initializer_func='he_uniform')\n",
    "        self.l2 = layer.Linear(hidden_size, initializer_func='he_uniform')\n",
    "        self.l3 = layer.Linear(out_size, initializer_func='he_uniform')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        y = f.activation.relu(y)\n",
    "        y = self.l2(y)\n",
    "        y = f.activation.relu(y)\n",
    "        y = self.l3(y)\n",
    "        y = f.activation.softmax(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nariflow.optimizer.Adam.Adam at 0x22558d3b9a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Models(hidden_size, out_size)\n",
    "\n",
    "optimizers = optimizer.Adam(lr)\n",
    "\n",
    "optimizers.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Variable(np.array(X_train))\n",
    "\n",
    "y_train = Variable(y_train)\n",
    "\n",
    "dataset = DataSet(X_train, y_train)\n",
    "\n",
    "dataset.batch_setup(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(X_train, y_train):\n",
    "    with GradientTape() as tape:\n",
    "        \n",
    "        y_pred = model(X_train)\n",
    "        loss = f.loss.categorical_crossentropy(y_train, y_pred)\n",
    "        \n",
    "    tape.CalcGradient()\n",
    "    optimizers.update()\n",
    "    \n",
    "    if j % 5 == 0:\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931407228640074\n",
      "0.6741362090424373\n",
      "0.6272608113703272\n",
      "0.6048838802298484\n",
      "0.5580642166656314\n",
      "0.5475145793575171\n",
      "0.6273634052601446\n",
      "0.6069214026752011\n",
      "0.5712169291277811\n",
      "0.5981289861829943\n",
      "0.5476197220981411\n",
      "0.5421274577317076\n",
      "0.5987641682999968\n",
      "0.5799741633662309\n",
      "0.49922529881181066\n",
      "0.60591609933516\n",
      "0.6187848188513365\n",
      "0.6085326457043315\n",
      "0.5585452778533283\n",
      "0.6318999678067682\n",
      "0.6038626291823477\n",
      "0.6122277782852593\n",
      "0.5790797235995274\n",
      "0.6091184825342222\n",
      "0.5018586994665484\n",
      "0.5317711946542125\n",
      "0.5268654167353759\n",
      "0.6085641482254808\n",
      "0.6133390625239477\n",
      "0.5572131517983423\n",
      "total_time :  0.33904194831848145\n",
      "1\n",
      "0.6214051107974332\n",
      "0.5399282172150237\n",
      "0.6129749685117989\n",
      "0.5845883284979599\n",
      "0.5323828580453936\n",
      "0.5212409276851995\n",
      "0.5947679284889317\n",
      "0.5824759164788078\n",
      "0.5621924842762374\n",
      "0.5621053927626063\n",
      "0.5118860209193236\n",
      "0.5336006183090586\n",
      "0.5701090037207992\n",
      "0.5619998082488208\n",
      "0.497694653462761\n",
      "0.5748429128753142\n",
      "0.6101357784207604\n",
      "0.5938733820326373\n",
      "0.5404350955162883\n",
      "0.6300680992410372\n",
      "0.59020124147283\n",
      "0.5900889287302826\n",
      "0.5768033634036063\n",
      "0.6037888421544723\n",
      "0.4954139243900626\n",
      "0.5209089093560946\n",
      "0.5080680964606976\n",
      "0.5908341364218327\n",
      "0.5970871315163703\n",
      "0.5585869765174176\n",
      "total_time :  0.6700780391693115\n",
      "2\n",
      "0.6195663139676799\n",
      "0.5311200431090133\n",
      "0.6080588391151216\n",
      "0.5704380980862659\n",
      "0.5246637196521126\n",
      "0.5147458997578341\n",
      "0.5845555321446017\n",
      "0.5706021093553305\n",
      "0.5474322737437601\n",
      "0.5571686983293282\n",
      "0.5048039925503358\n",
      "0.5275714070249713\n",
      "0.5553348784789323\n",
      "0.5367838689352639\n",
      "0.4897079177405248\n",
      "0.5643716795326976\n",
      "0.5955729262257164\n",
      "0.5820321925985358\n",
      "0.5237819064184939\n",
      "0.6269267699677173\n",
      "0.58333706616644\n",
      "0.575612378537487\n",
      "0.575048090128561\n",
      "0.5994121340892784\n",
      "0.49349533177499083\n",
      "0.5195721081573839\n",
      "0.49883790011283885\n",
      "0.5818794477637063\n",
      "0.5874175675140423\n",
      "0.5501330279710968\n",
      "total_time :  1.0250322818756104\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    for j in range(np.ceil((len(dataset) / batch_size)).astype('int')):\n",
    "\n",
    "        train_set, val_set = next(dataset)\n",
    "\n",
    "        train_step(train_set, val_set)\n",
    "\n",
    "    print('total_time : ', time.time() - start_time)\n",
    "\n",
    "    dataset.reset()\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = Variable(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489751887810141"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.argmax(y_pred.data, axis = -1), \n",
    "               np.argmax(y_test.data, axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75736568457539"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_pred.data, axis = -1), \n",
    "               np.argmax(y_test.data, axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 174,  120],\n",
       "       [ 440, 1574]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_pred.data, axis = -1),\n",
    "               np.argmax(y_test.data, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 공식 도큐의 Accuracy는 74%이다.\n",
    "### 결론 : 다중분류도 문제없이 작동한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
