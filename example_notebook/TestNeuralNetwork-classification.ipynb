{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nariflow import start_initializer\n",
    "\n",
    "start_initializer().initializer('tape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nariflow import Variable\n",
    "from nariflow import optimizer\n",
    "from nariflow import GradientTape\n",
    "#from nariflow import calc_gradient\n",
    "from nariflow import layer\n",
    "from nariflow.models import Model\n",
    "from nariflow import functions as f\n",
    "from nariflow.core import elementary_function as ef\n",
    "from nariflow.core import shape_function as sf\n",
    "from nariflow.utils import DataSet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip\n",
      "1671168/1668792 [==============================] - 0s 0us/step\n",
      "1679360/1668792 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
    "                        extract=True, cache_dir='.')\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop un-used columns.\n",
    "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7383 train examples\n",
      "1846 validation examples\n",
      "2308 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processing = pd.concat([pd.get_dummies(train.loc[:, train.apply(lambda x : x.dtype == 'object')]),\n",
    "           train.loc[:,train.apply(lambda x : x.dtype != 'object')].apply(lambda x : (x - min(x)) / (max(x) - min(x)) )], \n",
    "          axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_processing.drop(['target'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processing = pd.concat([pd.get_dummies(test.loc[:, test.apply(lambda x : x.dtype == 'object')]),\n",
    "           test.loc[:,test.apply(lambda x : x.dtype != 'object')].apply(lambda x : (x - min(x)) / (max(x) - min(x)) )], \n",
    "          axis = 1)\n",
    "\n",
    "test_processing = pd.concat([pd.DataFrame(columns = train_processing.columns),\n",
    "           test_processing])[train_processing.columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(pd.get_dummies(test_processing.loc[:,'target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= test_processing.drop(['target'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(pd.get_dummies(train_processing.loc[:,'target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.2\n",
    "max_iter = 10000\n",
    "hidden_size = 200\n",
    "out_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models(Model):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.l1 = layer.Linear(hidden_size, initializer_func='he_uniform')\n",
    "        self.l2 = layer.Linear(hidden_size, initializer_func='he_uniform')\n",
    "        self.l3 = layer.Linear(out_size, initializer_func='he_uniform')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        y = f.activation.relu(y)\n",
    "        y = self.l2(y)\n",
    "        y = f.activation.relu(y)\n",
    "        y = self.l3(y)\n",
    "        y = f.activation.softmax(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nariflow.optimizer.Adam.Adam at 0x1b65f82ac70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Models(hidden_size, out_size)\n",
    "\n",
    "optimizers = optimizer.Adam(lr)\n",
    "\n",
    "optimizers.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Variable(np.array(X_train))\n",
    "\n",
    "y_train = Variable(y_train)\n",
    "\n",
    "dataset = DataSet(X_train, y_train)\n",
    "\n",
    "dataset.batch_setup(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(X_train, y_train):\n",
    "    with GradientTape() as tape:\n",
    "        \n",
    "        y_pred = model(X_train)\n",
    "        loss = f.loss.categorical_crossentropy(y_train, y_pred)\n",
    "        \n",
    "    tape.CalcGradient()\n",
    "    optimizers.update()\n",
    "    \n",
    "    if j % 5 == 0:\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931710143988028\n",
      "0.6747361489132182\n",
      "0.6104166374589173\n",
      "0.6161155502435084\n",
      "0.6229973030010332\n",
      "0.57507054591286\n",
      "0.5603498083641721\n",
      "0.6208305135455268\n",
      "0.5732304415842362\n",
      "0.5585950801140338\n",
      "0.5835798382805981\n",
      "0.6019765777592596\n",
      "0.6155254069849577\n",
      "0.6075535375960525\n",
      "0.5889668796566376\n",
      "0.5811839938514151\n",
      "0.5622672931382656\n",
      "0.5450015809450296\n",
      "0.49629742647393194\n",
      "0.5649209534835762\n",
      "0.6165470683459991\n",
      "0.5469434895707134\n",
      "0.5394717551673263\n",
      "0.6194448458927704\n",
      "0.6135445751981775\n",
      "0.6253503949262934\n",
      "0.558652501174907\n",
      "0.5295177105069991\n",
      "0.5756519495114181\n",
      "0.604016578100544\n",
      "total_time :  0.7114534378051758\n",
      "1\n",
      "0.6066421915783191\n",
      "0.6021742609670013\n",
      "0.6037662687391486\n",
      "0.6045256818364615\n",
      "0.601890679630805\n",
      "0.5551114018245555\n",
      "0.535898949619023\n",
      "0.5831050645946799\n",
      "0.5380806981871039\n",
      "0.5391701292160008\n",
      "0.5685245364308292\n",
      "0.5079758869372016\n",
      "0.564234953355271\n",
      "0.6008969188160939\n",
      "0.573142291706604\n",
      "0.5651949059555338\n",
      "0.535122576481444\n",
      "0.5349226835119844\n",
      "0.5027330334931708\n",
      "0.5426270008911014\n",
      "0.6101354983362298\n",
      "0.5316670253715942\n",
      "0.5240427344242543\n",
      "0.6106717501960885\n",
      "0.6088304828296094\n",
      "0.6088011684163281\n",
      "0.5577089120828004\n",
      "0.5208133446984237\n",
      "0.5630516807611258\n",
      "0.6026631897695248\n",
      "total_time :  1.4080088138580322\n",
      "2\n",
      "0.5987531360686004\n",
      "0.5997640356738292\n",
      "0.5933419341999211\n",
      "0.6025315899921575\n",
      "0.5975406400395297\n",
      "0.5456062987812836\n",
      "0.5312173345489313\n",
      "0.5783765113523236\n",
      "0.5197703361600537\n",
      "0.5196259153859565\n",
      "0.5646629956555967\n",
      "0.5029537550968073\n",
      "0.551092314414888\n",
      "0.5893360154546524\n",
      "0.564742198434673\n",
      "0.5593393140597671\n",
      "0.5349876357804142\n",
      "0.5170167378916052\n",
      "0.4996366338672606\n",
      "0.5329777792904595\n",
      "0.6037035628608922\n",
      "0.5212474603880658\n",
      "0.5153197722714379\n",
      "0.5961280162806741\n",
      "0.6005153729070432\n",
      "0.5933403455216181\n",
      "0.5569257809619321\n",
      "0.519228414980998\n",
      "0.5546350476000561\n",
      "0.5998318502526195\n",
      "total_time :  2.1245768070220947\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    for j in range(np.ceil((len(dataset) / batch_size)).astype('int')):\n",
    "\n",
    "        train_set, val_set = next(dataset)\n",
    "\n",
    "        train_step(train_set, val_set)\n",
    "\n",
    "    print('total_time : ', time.time() - start_time)\n",
    "\n",
    "    dataset.reset()\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = Variable(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8476821192052981"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.argmax(y_pred.data, axis = -1), \n",
    "               np.argmax(y_test.data, axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608318890814558"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_pred.data, axis = -1), \n",
    "               np.argmax(y_test.data, axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 220,  177],\n",
       "       [ 375, 1536]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_pred.data, axis = -1),\n",
    "               np.argmax(y_test.data, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 공식 도큐의 Accuracy는 74%이다.\n",
    "### 결론 : 다중분류도 문제없이 작동한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
